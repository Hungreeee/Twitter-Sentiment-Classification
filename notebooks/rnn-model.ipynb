{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# keras\n",
    "from tensorflow import keras \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import set_random_seed\n",
    "\n",
    "# scipy\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "kv_model = KeyedVectors.load_word2vec_format('../utils/crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_glove_model(File):\n",
    "#   print(\"Loading Glove Model\")\n",
    "#   glove_model = {}\n",
    "#   with open(File, 'r', encoding=\"utf8\") as f:\n",
    "#     for line in f:\n",
    "#       split_line = line.split()\n",
    "#       word = split_line[0]\n",
    "#       embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "#       glove_model[word] = embedding\n",
    "#   print(f\"{len(glove_model)} words loaded!\")\n",
    "#   return glove_model\n",
    "\n",
    "# GloveModel = load_glove_model('../utils/glove.twitter.27B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('../data/preprocessed_data/feature_vectors_normal.npy', allow_pickle=True)\n",
    "y = np.load('../data/preprocessed_data/target_vectors_normal.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1436333\n",
      "Test set size 79796\n",
      "Validation set size 79797\n"
     ]
    }
   ],
   "source": [
    "X_train_split, X_test_split, y_train, y_test = train_test_split(X, y, train_size=0.9, random_state=13)\n",
    "X_test_split, X_val_split, y_test, y_val = train_test_split(X_test_split, y_test, train_size=0.5, random_state=13)\n",
    "\n",
    "print(\"Train set size:\", X_train_split.shape[0])\n",
    "print(\"Test set size\", X_test_split.shape[0])\n",
    "print(\"Validation set size\", X_val_split.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GloVe word embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us begin by vectorizing `X` and `y`. Here, we use `keras`'s tokenizer because it allows us to preprocess the data in a simpler and more convenient fashion than Pytorch's `torchtext` or `pytorch-nlp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  219191\n"
     ]
    }
   ],
   "source": [
    "# Initiate Keras tokenizer and vectorizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train_split)\n",
    "\n",
    "# Transfrom X into vectorized values\n",
    "X_train_transformed = tokenizer.texts_to_sequences(X_train_split)\n",
    "X_val_transformed = tokenizer.texts_to_sequences(X_val_split)\n",
    "X_test_transformed = tokenizer.texts_to_sequences(X_test_split)\n",
    "\n",
    "# View vocabulary size\n",
    "print(\"Vocabulary size: \", len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the label encoder to convert target data into (0, 1) instead of (0, 4)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Transform y into numerical values (0, 1)\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not yet finished. From the summary, it is quite noticeable that the lengths of the word vectors are largely uneven and deviating. This is why we should always consider padding/truncating during preprocessing. While this is not required for all deep learning model, uneven length in data may give the model a harder time to process batches and slow down the computation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics summary of vector lengths in X_transformed: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1595926.00\n",
       "mean          13.09\n",
       "std            7.23\n",
       "min            1.00\n",
       "25%            7.00\n",
       "50%           12.00\n",
       "75%           19.00\n",
       "90%           24.00\n",
       "97.5%         27.00\n",
       "max           53.00\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Statistics summary of vector lengths in X_transformed: ')\n",
    "pd.Series([len(text.split()) for text in X]).describe(percentiles=[.25, .5, .75, .9, .975]).apply(\"{0:.2f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA07klEQVR4nO3df1BU973/8Regu/hrl/gDkCsqra1KVRxRcdsm31ipm4R0YsUZTZyEGBNHLzqRbRVpvWhyewevmTbq9Vd7nVu8M6H+6FRbpWIpRpzWjT8wXH80MEmuuZjBBdIEVqmCwvn+0eHUVRtFIRQ+z8fMmXHP530++97PMLOvOXvOMcyyLEsAAAAGCu/qBgAAALoKQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYKxeXd3AP7LW1lZVV1drwIABCgsL6+p2AADAfbAsS1euXFFcXJzCwz//nA9B6HNUV1crPj6+q9sAAAAP4NKlSxo2bNjn1hCEPseAAQMk/XUhXS5XF3cDAADuRzAYVHx8vP09/nkIQp+j7ecwl8tFEAIAoJu5n8tauFgaAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFi9uroBdC8jVxV2dQvt9tG6tK5uAQDwD4ozQgAAwFgEIQAAYCyCEAAAMBZBCAAAGOuhgtC6desUFham5cuX2/uuX7+uzMxMDRo0SP3791d6erpqampCjquqqlJaWpr69u2r6OhorVixQjdv3gypOXr0qCZNmiSn06lRo0YpPz//jvffsmWLRo4cqcjISKWkpOjkyZMh4/fTCwAAMNcDB6FTp07ppz/9qSZMmBCyPysrSwcOHNDevXtVWlqq6upqzZ492x5vaWlRWlqampubdfz4ce3cuVP5+fnKzc21ay5evKi0tDRNnz5d5eXlWr58uV5++WUdPnzYrtm9e7d8Pp/WrFmjM2fOKCkpSV6vV7W1tffdCwAAMFuYZVlWew+6evWqJk2apK1bt+pHP/qRJk6cqA0bNqihoUFDhgxRQUGB5syZI0mqqKjQ2LFj5ff7NW3aNB06dEhPP/20qqurFRMTI0navn27srOzVVdXJ4fDoezsbBUWFur8+fP2e86bN0/19fUqKiqSJKWkpGjKlCnavHmzJKm1tVXx8fFatmyZVq1adV+93EswGJTb7VZDQ4NcLld7l6lH4vZ5AMA/uvZ8fz/QGaHMzEylpaUpNTU1ZH9ZWZlu3LgRsn/MmDEaPny4/H6/JMnv92v8+PF2CJIkr9erYDCoCxcu2DW3z+31eu05mpubVVZWFlITHh6u1NRUu+Z+egEAAGZr9wMVd+3apTNnzujUqVN3jAUCATkcDkVFRYXsj4mJUSAQsGtuDUFt421jn1cTDAZ17do1ffbZZ2ppablrTUVFxX33crumpiY1NTXZr4PB4F3rAABAz9CuM0KXLl3Sq6++qrfeekuRkZGd1VOXycvLk9vttrf4+PiubgkAAHSidgWhsrIy1dbWatKkSerVq5d69eql0tJSbdq0Sb169VJMTIyam5tVX18fclxNTY1iY2MlSbGxsXfcudX2+l41LpdLffr00eDBgxUREXHXmlvnuFcvt8vJyVFDQ4O9Xbp06f4XBwAAdDvtCkIzZszQuXPnVF5ebm+TJ0/W/Pnz7X/37t1bJSUl9jGVlZWqqqqSx+ORJHk8Hp07dy7k7q7i4mK5XC4lJibaNbfO0VbTNofD4VBycnJITWtrq0pKSuya5OTke/ZyO6fTKZfLFbIBAICeq13XCA0YMEDjxo0L2devXz8NGjTI3r9w4UL5fD4NHDhQLpdLy5Ytk8fjse/SmjlzphITE/X8889r/fr1CgQCWr16tTIzM+V0OiVJixcv1ubNm7Vy5Uq99NJLOnLkiPbs2aPCwr/dseTz+ZSRkaHJkydr6tSp2rBhgxobG7VgwQJJktvtvmcvAADAbB3+v8+/+eabCg8PV3p6upqamuT1erV161Z7PCIiQgcPHtSSJUvk8XjUr18/ZWRk6PXXX7drEhISVFhYqKysLG3cuFHDhg3Tjh075PV67Zq5c+eqrq5Oubm5CgQCmjhxooqKikIuoL5XLwAAwGwP9BwhU/AcoTvxHCEAwD+6Tn+OEAAAQE9AEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGKtdQWjbtm2aMGGCXC6XXC6XPB6PDh06ZI8//vjjCgsLC9kWL14cMkdVVZXS0tLUt29fRUdHa8WKFbp582ZIzdGjRzVp0iQ5nU6NGjVK+fn5d/SyZcsWjRw5UpGRkUpJSdHJkydDxq9fv67MzEwNGjRI/fv3V3p6umpqatrzcQEAQA/XriA0bNgwrVu3TmVlZTp9+rS+9a1v6ZlnntGFCxfsmldeeUWXL1+2t/Xr19tjLS0tSktLU3Nzs44fP66dO3cqPz9fubm5ds3FixeVlpam6dOnq7y8XMuXL9fLL7+sw4cP2zW7d++Wz+fTmjVrdObMGSUlJcnr9aq2ttauycrK0oEDB7R3716Vlpaqurpas2fPfqBFAgAAPVOYZVnWw0wwcOBAvfHGG1q4cKEef/xxTZw4URs2bLhr7aFDh/T000+rurpaMTExkqTt27crOztbdXV1cjgcys7OVmFhoc6fP28fN2/ePNXX16uoqEiSlJKSoilTpmjz5s2SpNbWVsXHx2vZsmVatWqVGhoaNGTIEBUUFGjOnDmSpIqKCo0dO1Z+v1/Tpk27r88WDAbldrvV0NAgl8v1oEvUo4xcVdjVLbTbR+vSuroFAMAXqD3f3w98jVBLS4t27dqlxsZGeTwee/9bb72lwYMHa9y4ccrJydFf/vIXe8zv92v8+PF2CJIkr9erYDBon1Xy+/1KTU0NeS+v1yu/3y9Jam5uVllZWUhNeHi4UlNT7ZqysjLduHEjpGbMmDEaPny4XXM3TU1NCgaDIRsAAOi5erX3gHPnzsnj8ej69evq37+/9u3bp8TEREnSc889pxEjRiguLk5nz55Vdna2Kisr9atf/UqSFAgEQkKQJPt1IBD43JpgMKhr167ps88+U0tLy11rKioq7DkcDoeioqLuqGl7n7vJy8vTa6+91s4VAQAA3VW7g9Do0aNVXl6uhoYG/fKXv1RGRoZKS0uVmJioRYsW2XXjx4/X0KFDNWPGDH344Yf68pe/3KGNd4acnBz5fD77dTAYVHx8fBd2BAAAOlO7fxpzOBwaNWqUkpOTlZeXp6SkJG3cuPGutSkpKZKkDz74QJIUGxt7x51bba9jY2M/t8blcqlPnz4aPHiwIiIi7lpz6xzNzc2qr6//uzV343Q67Tvi2jYAANBztfuM0O1aW1vV1NR017Hy8nJJ0tChQyVJHo9H//Zv/6ba2lpFR0dLkoqLi+Vyueyf1zwej37729+GzFNcXGxfh+RwOJScnKySkhLNmjXL7qGkpERLly6VJCUnJ6t3794qKSlRenq6JKmyslJVVVUh1zN1te544TEAAD1Ju4JQTk6OnnzySQ0fPlxXrlxRQUGBjh49qsOHD+vDDz9UQUGBnnrqKQ0aNEhnz55VVlaWHnvsMU2YMEGSNHPmTCUmJur555/X+vXrFQgEtHr1amVmZsrpdEqSFi9erM2bN2vlypV66aWXdOTIEe3Zs0eFhX8LDT6fTxkZGZo8ebKmTp2qDRs2qLGxUQsWLJAkud1uLVy4UD6fTwMHDpTL5dKyZcvk8Xju+44xAADQ87UrCNXW1uqFF17Q5cuX5Xa7NWHCBB0+fFjf/va3denSJf3+97+3Q0l8fLzS09O1evVq+/iIiAgdPHhQS5YskcfjUb9+/ZSRkaHXX3/drklISFBhYaGysrK0ceNGDRs2TDt27JDX67Vr5s6dq7q6OuXm5ioQCGjixIkqKioKuYD6zTffVHh4uNLT09XU1CSv16utW7c+zFoBAIAe5qGfI9STdfZzhPhp7IvBc4QAwCxfyHOEAAAAujuCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADG6tXVDQCdbeSqwq5uod0+WpfW1S0AgBE4IwQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGalcQ2rZtmyZMmCCXyyWXyyWPx6NDhw7Z49evX1dmZqYGDRqk/v37Kz09XTU1NSFzVFVVKS0tTX379lV0dLRWrFihmzdvhtQcPXpUkyZNktPp1KhRo5Sfn39HL1u2bNHIkSMVGRmplJQUnTx5MmT8fnoBAABma1cQGjZsmNatW6eysjKdPn1a3/rWt/TMM8/owoULkqSsrCwdOHBAe/fuVWlpqaqrqzV79mz7+JaWFqWlpam5uVnHjx/Xzp07lZ+fr9zcXLvm4sWLSktL0/Tp01VeXq7ly5fr5Zdf1uHDh+2a3bt3y+fzac2aNTpz5oySkpLk9XpVW1tr19yrFwAAgDDLsqyHmWDgwIF64403NGfOHA0ZMkQFBQWaM2eOJKmiokJjx46V3+/XtGnTdOjQIT399NOqrq5WTEyMJGn79u3Kzs5WXV2dHA6HsrOzVVhYqPPnz9vvMW/ePNXX16uoqEiSlJKSoilTpmjz5s2SpNbWVsXHx2vZsmVatWqVGhoa7tnL/QgGg3K73WpoaJDL5XqYZbqrkasKO3xO9AwfrUvr6hYAoNtqz/f3A18j1NLSol27dqmxsVEej0dlZWW6ceOGUlNT7ZoxY8Zo+PDh8vv9kiS/36/x48fbIUiSvF6vgsGgfVbJ7/eHzNFW0zZHc3OzysrKQmrCw8OVmppq19xPL3fT1NSkYDAYsgEAgJ6r3UHo3Llz6t+/v5xOpxYvXqx9+/YpMTFRgUBADodDUVFRIfUxMTEKBAKSpEAgEBKC2sbbxj6vJhgM6tq1a/rkk0/U0tJy15pb57hXL3eTl5cnt9ttb/Hx8fe3KAAAoFtqdxAaPXq0ysvLdeLECS1ZskQZGRn605/+1Bm9feFycnLU0NBgb5cuXerqlgAAQCfq1d4DHA6HRo0aJUlKTk7WqVOntHHjRs2dO1fNzc2qr68PORNTU1Oj2NhYSVJsbOwdd3e13cl1a83td3fV1NTI5XKpT58+ioiIUERExF1rbp3jXr3cjdPplNPpbMdqAACA7uyhnyPU2tqqpqYmJScnq3fv3iopKbHHKisrVVVVJY/HI0nyeDw6d+5cyN1dxcXFcrlcSkxMtGtunaOtpm0Oh8Oh5OTkkJrW1laVlJTYNffTCwAAQLvOCOXk5OjJJ5/U8OHDdeXKFRUUFOjo0aM6fPiw3G63Fi5cKJ/Pp4EDB8rlcmnZsmXyeDz2XVozZ85UYmKinn/+ea1fv16BQECrV69WZmamfSZm8eLF2rx5s1auXKmXXnpJR44c0Z49e1RY+Lc7rHw+nzIyMjR58mRNnTpVGzZsUGNjoxYsWCBJ99ULAABAu4JQbW2tXnjhBV2+fFlut1sTJkzQ4cOH9e1vf1uS9Oabbyo8PFzp6elqamqS1+vV1q1b7eMjIiJ08OBBLVmyRB6PR/369VNGRoZef/11uyYhIUGFhYXKysrSxo0bNWzYMO3YsUNer9eumTt3rurq6pSbm6tAIKCJEyeqqKgo5ALqe/UCAADw0M8R6sl4jhC6Cs8RAoAH94U8RwgAAKC7IwgBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIzVriCUl5enKVOmaMCAAYqOjtasWbNUWVkZUvP4448rLCwsZFu8eHFITVVVldLS0tS3b19FR0drxYoVunnzZkjN0aNHNWnSJDmdTo0aNUr5+fl39LNlyxaNHDlSkZGRSklJ0cmTJ0PGr1+/rszMTA0aNEj9+/dXenq6ampq2vORAQBAD9auIFRaWqrMzEy98847Ki4u1o0bNzRz5kw1NjaG1L3yyiu6fPmyva1fv94ea2lpUVpampqbm3X8+HHt3LlT+fn5ys3NtWsuXryotLQ0TZ8+XeXl5Vq+fLlefvllHT582K7ZvXu3fD6f1qxZozNnzigpKUler1e1tbV2TVZWlg4cOKC9e/eqtLRU1dXVmj17drsXCQAA9ExhlmVZD3pwXV2doqOjVVpaqscee0zSX88ITZw4URs2bLjrMYcOHdLTTz+t6upqxcTESJK2b9+u7Oxs1dXVyeFwKDs7W4WFhTp//rx93Lx581RfX6+ioiJJUkpKiqZMmaLNmzdLklpbWxUfH69ly5Zp1apVamho0JAhQ1RQUKA5c+ZIkioqKjR27Fj5/X5Nmzbtnp8vGAzK7XaroaFBLpfrQZfp7xq5qrDD5wS6ykfr0rq6BQCQ1L7v74e6RqihoUGSNHDgwJD9b731lgYPHqxx48YpJydHf/nLX+wxv9+v8ePH2yFIkrxer4LBoC5cuGDXpKamhszp9Xrl9/slSc3NzSorKwupCQ8PV2pqql1TVlamGzduhNSMGTNGw4cPt2tu19TUpGAwGLIBAICeq9eDHtja2qrly5frG9/4hsaNG2fvf+655zRixAjFxcXp7Nmzys7OVmVlpX71q19JkgKBQEgIkmS/DgQCn1sTDAZ17do1ffbZZ2ppablrTUVFhT2Hw+FQVFTUHTVt73O7vLw8vfbaa+1cCQAA0F09cBDKzMzU+fPn9Yc//CFk/6JFi+x/jx8/XkOHDtWMGTP04Ycf6stf/vKDd/oFyMnJkc/ns18Hg0HFx8d3YUcAAKAzPdBPY0uXLtXBgwf19ttva9iwYZ9bm5KSIkn64IMPJEmxsbF33LnV9jo2NvZza1wul/r06aPBgwcrIiLirjW3ztHc3Kz6+vq/W3M7p9Mpl8sVsgEAgJ6rXUHIsiwtXbpU+/bt05EjR5SQkHDPY8rLyyVJQ4cOlSR5PB6dO3cu5O6u4uJiuVwuJSYm2jUlJSUh8xQXF8vj8UiSHA6HkpOTQ2paW1tVUlJi1yQnJ6t3794hNZWVlaqqqrJrAACA2dr101hmZqYKCgr061//WgMGDLCvtXG73erTp48+/PBDFRQU6KmnntKgQYN09uxZZWVl6bHHHtOECRMkSTNnzlRiYqKef/55rV+/XoFAQKtXr1ZmZqacTqckafHixdq8ebNWrlypl156SUeOHNGePXtUWPi3u6x8Pp8yMjI0efJkTZ06VRs2bFBjY6MWLFhg97Rw4UL5fD4NHDhQLpdLy5Ytk8fjua87xgAAQM/XriC0bds2SX+9Rf5WP//5z/Xiiy/K4XDo97//vR1K4uPjlZ6ertWrV9u1EREROnjwoJYsWSKPx6N+/fopIyNDr7/+ul2TkJCgwsJCZWVlaePGjRo2bJh27Nghr9dr18ydO1d1dXXKzc1VIBDQxIkTVVRUFHIB9Ztvvqnw8HClp6erqalJXq9XW7dubdcCAQCAnuuhniPU0/EcIeD+8RwhAP8ovrDnCAEAAHRnBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLHaFYTy8vI0ZcoUDRgwQNHR0Zo1a5YqKytDaq5fv67MzEwNGjRI/fv3V3p6umpqakJqqqqqlJaWpr59+yo6OlorVqzQzZs3Q2qOHj2qSZMmyel0atSoUcrPz7+jny1btmjkyJGKjIxUSkqKTp482e5eAACAudoVhEpLS5WZmal33nlHxcXFunHjhmbOnKnGxka7JisrSwcOHNDevXtVWlqq6upqzZ492x5vaWlRWlqampubdfz4ce3cuVP5+fnKzc21ay5evKi0tDRNnz5d5eXlWr58uV5++WUdPnzYrtm9e7d8Pp/WrFmjM2fOKCkpSV6vV7W1tffdCwAAMFuYZVnWgx5cV1en6OholZaW6rHHHlNDQ4OGDBmigoICzZkzR5JUUVGhsWPHyu/3a9q0aTp06JCefvppVVdXKyYmRpK0fft2ZWdnq66uTg6HQ9nZ2SosLNT58+ft95o3b57q6+tVVFQkSUpJSdGUKVO0efNmSVJra6vi4+O1bNkyrVq16r56uZdgMCi3262Ghga5XK4HXaa/a+Sqwg6fE+gqH61L6+oWAEBS+76/H+oaoYaGBknSwIEDJUllZWW6ceOGUlNT7ZoxY8Zo+PDh8vv9kiS/36/x48fbIUiSvF6vgsGgLly4YNfcOkdbTdsczc3NKisrC6kJDw9XamqqXXM/vdyuqalJwWAwZAMAAD3XAweh1tZWLV++XN/4xjc0btw4SVIgEJDD4VBUVFRIbUxMjAKBgF1zawhqG28b+7yaYDCoa9eu6ZNPPlFLS8tda26d41693C4vL09ut9ve4uPj73M1AABAd/TAQSgzM1Pnz5/Xrl27OrKfLpWTk6OGhgZ7u3TpUle3BAAAOlGvBzlo6dKlOnjwoI4dO6Zhw4bZ+2NjY9Xc3Kz6+vqQMzE1NTWKjY21a26/u6vtTq5ba26/u6umpkYul0t9+vRRRESEIiIi7lpz6xz36uV2TqdTTqezHSsBAAC6s3adEbIsS0uXLtW+fft05MgRJSQkhIwnJyerd+/eKikpsfdVVlaqqqpKHo9HkuTxeHTu3LmQu7uKi4vlcrmUmJho19w6R1tN2xwOh0PJyckhNa2trSopKbFr7qcXAABgtnadEcrMzFRBQYF+/etfa8CAAfa1Nm63W3369JHb7dbChQvl8/k0cOBAuVwuLVu2TB6Px75La+bMmUpMTNTzzz+v9evXKxAIaPXq1crMzLTPxixevFibN2/WypUr9dJLL+nIkSPas2ePCgv/dpeVz+dTRkaGJk+erKlTp2rDhg1qbGzUggUL7J7u1QuAjtMd74LkTjcA7QpC27ZtkyQ9/vjjIft//vOf68UXX5QkvfnmmwoPD1d6erqamprk9Xq1detWuzYiIkIHDx7UkiVL5PF41K9fP2VkZOj111+3axISElRYWKisrCxt3LhRw4YN044dO+T1eu2auXPnqq6uTrm5uQoEApo4caKKiopCLqC+Vy8AAMBsD/UcoZ6O5wgBPRtnhICe6Qt7jhAAAEB3RhACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABir3UHo2LFj+s53vqO4uDiFhYVp//79IeMvvviiwsLCQrYnnngipObTTz/V/Pnz5XK5FBUVpYULF+rq1ashNWfPntWjjz6qyMhIxcfHa/369Xf0snfvXo0ZM0aRkZEaP368fvvb34aMW5al3NxcDR06VH369FFqaqref//99n5kAADQQ7U7CDU2NiopKUlbtmz5uzVPPPGELl++bG+/+MUvQsbnz5+vCxcuqLi4WAcPHtSxY8e0aNEiezwYDGrmzJkaMWKEysrK9MYbb2jt2rX62c9+ZtccP35czz77rBYuXKh3331Xs2bN0qxZs3T+/Hm7Zv369dq0aZO2b9+uEydOqF+/fvJ6vbp+/Xp7PzYAAOiBwizLsh744LAw7du3T7NmzbL3vfjii6qvr7/jTFGb9957T4mJiTp16pQmT54sSSoqKtJTTz2ljz/+WHFxcdq2bZt++MMfKhAIyOFwSJJWrVql/fv3q6KiQpI0d+5cNTY26uDBg/bc06ZN08SJE7V9+3ZZlqW4uDh973vf0/e//31JUkNDg2JiYpSfn6958+bd8/MFg0G53W41NDTI5XI9yBJ9rpGrCjt8TgD376N1aV3dAoBO0J7v7065Rujo0aOKjo7W6NGjtWTJEv35z3+2x/x+v6KiouwQJEmpqakKDw/XiRMn7JrHHnvMDkGS5PV6VVlZqc8++8yuSU1NDXlfr9crv98vSbp48aICgUBIjdvtVkpKil1zu6amJgWDwZANAAD0XB0ehJ544gn993//t0pKSvTv//7vKi0t1ZNPPqmWlhZJUiAQUHR0dMgxvXr10sCBAxUIBOyamJiYkJq21/equXX81uPuVnO7vLw8ud1ue4uPj2/35wcAAN1Hr46e8NafnMaPH68JEyboy1/+so4ePaoZM2Z09Nt1qJycHPl8Pvt1MBgkDAEA0IN1+u3zX/rSlzR48GB98MEHkqTY2FjV1taG1Ny8eVOffvqpYmNj7ZqampqQmrbX96q5dfzW4+5Wczun0ymXyxWyAQCAnqvTg9DHH3+sP//5zxo6dKgkyePxqL6+XmVlZXbNkSNH1NraqpSUFLvm2LFjunHjhl1TXFys0aNH65FHHrFrSkpKQt6ruLhYHo9HkpSQkKDY2NiQmmAwqBMnTtg1AADAbO0OQlevXlV5ebnKy8sl/fWi5PLyclVVVenq1atasWKF3nnnHX300UcqKSnRM888o1GjRsnr9UqSxo4dqyeeeEKvvPKKTp48qT/+8Y9aunSp5s2bp7i4OEnSc889J4fDoYULF+rChQvavXu3Nm7cGPKz1auvvqqioiL9+Mc/VkVFhdauXavTp09r6dKlkv56R9vy5cv1ox/9SL/5zW907tw5vfDCC4qLiwu5yw0AAJir3dcInT59WtOnT7dft4WTjIwMbdu2TWfPntXOnTtVX1+vuLg4zZw5U//6r/8qp9NpH/PWW29p6dKlmjFjhsLDw5Wenq5NmzbZ4263W7/73e+UmZmp5ORkDR48WLm5uSHPGvr617+ugoICrV69Wj/4wQ/0la98Rfv379e4cePsmpUrV6qxsVGLFi1SfX29vvnNb6qoqEiRkZHt/dgAAKAHeqjnCPV0PEcI6Nl4jhDQM3X5c4QAAAC6A4IQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICx2h2Ejh07pu985zuKi4tTWFiY9u/fHzJuWZZyc3M1dOhQ9enTR6mpqXr//fdDaj799FPNnz9fLpdLUVFRWrhwoa5evRpSc/bsWT366KOKjIxUfHy81q9ff0cve/fu1ZgxYxQZGanx48frt7/9bbt7AQAA5mp3EGpsbFRSUpK2bNly1/H169dr06ZN2r59u06cOKF+/frJ6/Xq+vXrds38+fN14cIFFRcX6+DBgzp27JgWLVpkjweDQc2cOVMjRoxQWVmZ3njjDa1du1Y/+9nP7Jrjx4/r2Wef1cKFC/Xuu+9q1qxZmjVrls6fP9+uXgAAgLnCLMuyHvjgsDDt27dPs2bNkvTXMzBxcXH63ve+p+9///uSpIaGBsXExCg/P1/z5s3Te++9p8TERJ06dUqTJ0+WJBUVFempp57Sxx9/rLi4OG3btk0//OEPFQgE5HA4JEmrVq3S/v37VVFRIUmaO3euGhsbdfDgQbufadOmaeLEidq+fft99XIvwWBQbrdbDQ0NcrlcD7pMf9fIVYUdPieA+/fRurSubgFAJ2jP93eHXiN08eJFBQIBpaam2vvcbrdSUlLk9/slSX6/X1FRUXYIkqTU1FSFh4frxIkTds1jjz1mhyBJ8nq9qqys1GeffWbX3Po+bTVt73M/vQAAALP16sjJAoGAJCkmJiZkf0xMjD0WCAQUHR0d2kSvXho4cGBITUJCwh1ztI098sgjCgQC93yfe/Vyu6amJjU1Ndmvg8HgPT4xAADozrhr7BZ5eXlyu932Fh8f39UtAQCATtShQSg2NlaSVFNTE7K/pqbGHouNjVVtbW3I+M2bN/Xpp5+G1Nxtjlvf4+/V3Dp+r15ul5OTo4aGBnu7dOnSfXxqAADQXXVoEEpISFBsbKxKSkrsfcFgUCdOnJDH45EkeTwe1dfXq6yszK45cuSIWltblZKSYtccO3ZMN27csGuKi4s1evRoPfLII3bNre/TVtP2PvfTy+2cTqdcLlfIBgAAeq52B6GrV6+qvLxc5eXlkv56UXJ5ebmqqqoUFham5cuX60c/+pF+85vf6Ny5c3rhhRcUFxdn31k2duxYPfHEE3rllVd08uRJ/fGPf9TSpUs1b948xcXFSZKee+45ORwOLVy4UBcuXNDu3bu1ceNG+Xw+u49XX31VRUVF+vGPf6yKigqtXbtWp0+f1tKlSyXpvnoBAABma/fF0qdPn9b06dPt123hJCMjQ/n5+Vq5cqUaGxu1aNEi1dfX65vf/KaKiooUGRlpH/PWW29p6dKlmjFjhsLDw5Wenq5NmzbZ4263W7/73e+UmZmp5ORkDR48WLm5uSHPGvr617+ugoICrV69Wj/4wQ/0la98Rfv379e4cePsmvvpBQAAmOuhniPU0/EcIaBn4zlCQM/UZc8RAgAA6E4IQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYKxeXd0AAHSVkasKu7qFdvtoXVpXtwD0KJwRAgAAxiIIAQAAYxGEAACAsQhCAADAWB0ehNauXauwsLCQbcyYMfb49evXlZmZqUGDBql///5KT09XTU1NyBxVVVVKS0tT3759FR0drRUrVujmzZshNUePHtWkSZPkdDo1atQo5efn39HLli1bNHLkSEVGRiolJUUnT57s6I8LAAC6sU45I/S1r31Nly9ftrc//OEP9lhWVpYOHDigvXv3qrS0VNXV1Zo9e7Y93tLSorS0NDU3N+v48ePauXOn8vPzlZuba9dcvHhRaWlpmj59usrLy7V8+XK9/PLLOnz4sF2ze/du+Xw+rVmzRmfOnFFSUpK8Xq9qa2s74yMDAIBuKMyyLKsjJ1y7dq3279+v8vLyO8YaGho0ZMgQFRQUaM6cOZKkiooKjR07Vn6/X9OmTdOhQ4f09NNPq7q6WjExMZKk7du3Kzs7W3V1dXI4HMrOzlZhYaHOnz9vzz1v3jzV19erqKhIkpSSkqIpU6Zo8+bNkqTW1lbFx8dr2bJlWrVq1X19lmAwKLfbrYaGBrlcrodZlrvqjrfuAuha3D4P3Ft7vr875YzQ+++/r7i4OH3pS1/S/PnzVVVVJUkqKyvTjRs3lJqaateOGTNGw4cPl9/vlyT5/X6NHz/eDkGS5PV6FQwGdeHCBbvm1jnaatrmaG5uVllZWUhNeHi4UlNT7Zq7aWpqUjAYDNkAAEDP1eFBKCUlRfn5+SoqKtK2bdt08eJFPfroo7py5YoCgYAcDoeioqJCjomJiVEgEJAkBQKBkBDUNt429nk1wWBQ165d0yeffKKWlpa71rTNcTd5eXlyu932Fh8f/0BrAAAAuocOf7L0k08+af97woQJSklJ0YgRI7Rnzx716dOno9+uQ+Xk5Mjn89mvg8EgYQgAgB6s02+fj4qK0le/+lV98MEHio2NVXNzs+rr60NqampqFBsbK0mKjY294y6yttf3qnG5XOrTp48GDx6siIiIu9a0zXE3TqdTLpcrZAMAAD1Xpwehq1ev6sMPP9TQoUOVnJys3r17q6SkxB6vrKxUVVWVPB6PJMnj8ejcuXMhd3cVFxfL5XIpMTHRrrl1jraatjkcDoeSk5NDalpbW1VSUmLXAAAAdHgQ+v73v6/S0lJ99NFHOn78uL773e8qIiJCzz77rNxutxYuXCifz6e3335bZWVlWrBggTwej6ZNmyZJmjlzphITE/X888/rf/7nf3T48GGtXr1amZmZcjqdkqTFixfrf//3f7Vy5UpVVFRo69at2rNnj7Kysuw+fD6f/vM//1M7d+7Ue++9pyVLlqixsVELFizo6I8MAAC6qQ6/Rujjjz/Ws88+qz//+c8aMmSIvvnNb+qdd97RkCFDJElvvvmmwsPDlZ6erqamJnm9Xm3dutU+PiIiQgcPHtSSJUvk8XjUr18/ZWRk6PXXX7drEhISVFhYqKysLG3cuFHDhg3Tjh075PV67Zq5c+eqrq5Oubm5CgQCmjhxooqKiu64gBoAAJirw58j1JPwHCEA/2h4jhBwb13+HCEAAIDugCAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADCWEUFoy5YtGjlypCIjI5WSkqKTJ092dUsAAOAfQI8PQrt375bP59OaNWt05swZJSUlyev1qra2tqtbAwAAXazHB6Gf/OQneuWVV7RgwQIlJiZq+/bt6tu3r/7rv/6rq1sDAABdrFdXN9CZmpubVVZWppycHHtfeHi4UlNT5ff776hvampSU1OT/bqhoUGSFAwGO6W/1qa/dMq8AHqu4Vl7u7qFB3L+NW9XtwCDtH1vW5Z1z9oeHYQ++eQTtbS0KCYmJmR/TEyMKioq7qjPy8vTa6+9dsf++Pj4TusRAEzg3tDVHcBEV65ckdvt/tyaHh2E2isnJ0c+n89+3draqk8//VSDBg1SWFjYfc8TDAYVHx+vS5cuyeVydUarxmJtOw9r2zlY187D2nae7r62lmXpypUriouLu2dtjw5CgwcPVkREhGpqakL219TUKDY29o56p9Mpp9MZsi8qKuqB39/lcnXLP6DugLXtPKxt52BdOw9r23m689re60xQmx59sbTD4VBycrJKSkrsfa2trSopKZHH4+nCzgAAwD+CHn1GSJJ8Pp8yMjI0efJkTZ06VRs2bFBjY6MWLFjQ1a0BAIAu1uOD0Ny5c1VXV6fc3FwFAgFNnDhRRUVFd1xA3ZGcTqfWrFlzx89seHisbedhbTsH69p5WNvOY9Lahln3c28ZAABAD9SjrxECAAD4PAQhAABgLIIQAAAwFkEIAAAYiyDUCbZs2aKRI0cqMjJSKSkpOnnyZFe31O0cO3ZM3/nOdxQXF6ewsDDt378/ZNyyLOXm5mro0KHq06ePUlNT9f7773dNs91IXl6epkyZogEDBig6OlqzZs1SZWVlSM3169eVmZmpQYMGqX///kpPT7/joaS407Zt2zRhwgT7AXQej0eHDh2yx1nXjrFu3TqFhYVp+fLl9j7W9sGsXbtWYWFhIduYMWPscVPWlSDUwXbv3i2fz6c1a9bozJkzSkpKktfrVW1tbVe31q00NjYqKSlJW7Zsuev4+vXrtWnTJm3fvl0nTpxQv3795PV6df369S+40+6ltLRUmZmZeuedd1RcXKwbN25o5syZamxstGuysrJ04MAB7d27V6Wlpaqurtbs2bO7sOvuYdiwYVq3bp3Kysp0+vRpfetb39IzzzyjCxcuSGJdO8KpU6f005/+VBMmTAjZz9o+uK997Wu6fPmyvf3hD3+wx4xZVwsdaurUqVZmZqb9uqWlxYqLi7Py8vK6sKvuTZK1b98++3Vra6sVGxtrvfHGG/a++vp6y+l0Wr/4xS+6oMPuq7a21pJklZaWWpb113Xs3bu3tXfvXrvmvffesyRZfr+/q9rsth555BFrx44drGsHuHLlivWVr3zFKi4utv7f//t/1quvvmpZFn+zD2PNmjVWUlLSXcdMWlfOCHWg5uZmlZWVKTU11d4XHh6u1NRU+f3+LuysZ7l48aICgUDIOrvdbqWkpLDO7dTQ0CBJGjhwoCSprKxMN27cCFnbMWPGaPjw4axtO7S0tGjXrl1qbGyUx+NhXTtAZmam0tLSQtZQ4m/2Yb3//vuKi4vTl770Jc2fP19VVVWSzFrXHv9k6S/SJ598opaWljueWh0TE6OKioou6qrnCQQCknTXdW4bw721trZq+fLl+sY3vqFx48ZJ+uvaOhyOO/6zYdb2/pw7d04ej0fXr19X//79tW/fPiUmJqq8vJx1fQi7du3SmTNndOrUqTvG+Jt9cCkpKcrPz9fo0aN1+fJlvfbaa3r00Ud1/vx5o9aVIAQYKjMzU+fPnw+5JgAPZ/To0SovL1dDQ4N++ctfKiMjQ6WlpV3dVrd26dIlvfrqqyouLlZkZGRXt9OjPPnkk/a/J0yYoJSUFI0YMUJ79uxRnz59urCzLxY/jXWgwYMHKyIi4o6r6mtqahQbG9tFXfU8bWvJOj+4pUuX6uDBg3r77bc1bNgwe39sbKyam5tVX18fUs/a3h+Hw6FRo0YpOTlZeXl5SkpK0saNG1nXh1BWVqba2lpNmjRJvXr1Uq9evVRaWqpNmzapV69eiomJYW07SFRUlL761a/qgw8+MOpvliDUgRwOh5KTk1VSUmLva21tVUlJiTweTxd21rMkJCQoNjY2ZJ2DwaBOnDjBOt+DZVlaunSp9u3bpyNHjighISFkPDk5Wb179w5Z28rKSlVVVbG2D6C1tVVNTU2s60OYMWOGzp07p/LycnubPHmy5s+fb/+bte0YV69e1YcffqihQ4ea9Tfb1Vdr9zS7du2ynE6nlZ+fb/3pT3+yFi1aZEVFRVmBQKCrW+tWrly5Yr377rvWu+++a0myfvKTn1jvvvuu9X//93+WZVnWunXrrKioKOvXv/61dfbsWeuZZ56xEhISrGvXrnVx5//YlixZYrndbuvo0aPW5cuX7e0vf/mLXbN48WJr+PDh1pEjR6zTp09bHo/H8ng8Xdh197Bq1SqrtLTUunjxonX27Flr1apVVlhYmPW73/3OsizWtSPdeteYZbG2D+p73/uedfToUevixYvWH//4Rys1NdUaPHiwVVtba1mWOetKEOoE//Ef/2ENHz7ccjgc1tSpU6133nmnq1vqdt5++21L0h1bRkaGZVl/vYX+X/7lX6yYmBjL6XRaM2bMsCorK7u26W7gbmsqyfr5z39u11y7ds3653/+Z+uRRx6x+vbta333u9+1Ll++3HVNdxMvvfSSNWLECMvhcFhDhgyxZsyYYYcgy2JdO9LtQYi1fTBz5861hg4dajkcDuuf/umfrLlz51offPCBPW7KuoZZlmV1zbkoAACArsU1QgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAY6/8Dxk6RfvxGF48AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(text.split()) for text in X])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "For our case, we can see that the maximum size is quite short (50 tokens) so there is no need for truncation. However, padding will be performed to ensure that the vectors have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics summary of vector lengths in X_transformed: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1436333.00\n",
       "mean          25.00\n",
       "std            0.00\n",
       "min           25.00\n",
       "25%           25.00\n",
       "50%           25.00\n",
       "75%           25.00\n",
       "max           25.00\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform padding on X_transformed\n",
    "X_train_transformed = pad_sequences(X_train_transformed, maxlen=25, padding='post', truncating='post')\n",
    "X_val_transformed = pad_sequences(X_val_transformed, maxlen=25, padding='post', truncating='post')\n",
    "X_test_transformed = pad_sequences(X_test_transformed, maxlen=25, padding='post', truncating='post')\n",
    "\n",
    "print('Statistics summary of vector lengths in X_transformed: ')\n",
    "pd.Series([len(text) for text in X_train_transformed]).describe().apply(\"{0:.2f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(torch.tensor(X_train_transformed), torch.tensor(y_train).reshape(-1, 1))\n",
    "val_set = TensorDataset(torch.tensor(X_val_transformed), torch.tensor(y_val).reshape(-1, 1))\n",
    "test_set = TensorDataset(torch.tensor(X_test_transformed), torch.tensor(y_test).reshape(-1, 1))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=128)\n",
    "test_loader = DataLoader(test_set, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we may continue building the embedding word vectors from our built vocabulary. The idea is to loop through each item in our vocabulary to see for each word if GloVe has the embedding vectors for it. If yes, we may load it into our embeddings matrix; otherwise, we leave it as empty (fill with zeros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the vocabulary size of our data \n",
    "# (+1 is to add padding token, which is not initially included in the vocabulary)\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Embedding size. This is the default dimensions of the GloVe's embeddings.\n",
    "EMBEDDINGS_DIM = 300\n",
    "\n",
    "OUTPUT_SIZE = 1\n",
    "HIDDEN_SIZE = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate an empty matrix as a embeddings container\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDINGS_DIM))\n",
    "\n",
    "# Loading GloVe weights into our embedding matrix\n",
    "for word, index in tokenizer.word_index.items():\n",
    "  if word in kv_model:\n",
    "    embedding_matrix[index] = kv_model[word].copy()\n",
    "\n",
    "embedding_matrix = torch.FloatTensor(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the shape of the embedding matrix for dimensionality check. It should be (vocabulary size, embeddings dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([219192, 300])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural network (RNN) model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(13)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(13)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "cannot assign module before Module.__init__() call",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Personal folder\\Sentiment Analysis\\notebooks\\rnn-model.ipynb Cell 25\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     out, ht \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecurrent_stack(emb, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model \u001b[39m=\u001b[39m RNN(OUTPUT_SIZE, EMBEDDINGS_DIM, HIDDEN_SIZE, \u001b[39m2\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n",
      "\u001b[1;32md:\\Personal folder\\Sentiment Analysis\\notebooks\\rnn-model.ipynb Cell 25\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, output_size, embedding_dim, hidden_size, hidden_layer, dropout\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding\u001b[39m.\u001b[39mfrom_pretrained(embedding_matrix)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecurrent \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mRNN(input_size\u001b[39m=\u001b[39membedding_dim, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m            hidden_size\u001b[39m=\u001b[39mhidden_size, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m            num_layers\u001b[39m=\u001b[39mhidden_layer,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m            nonlinearity\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m           \u001b[39m#  dropout=dropout,\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m            bidirectional\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_layer \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     nn\u001b[39m.\u001b[39mLinear(in_features\u001b[39m=\u001b[39mhidden_layer, out_features\u001b[39m=\u001b[39moutput_size),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     nn\u001b[39m.\u001b[39mSigmoid()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Personal%20folder/Sentiment%20Analysis/notebooks/rnn-model.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Hung Nguyen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1643\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   1641\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Module):\n\u001b[0;32m   1642\u001b[0m     \u001b[39mif\u001b[39;00m modules \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1643\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m   1644\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcannot assign module before Module.__init__() call\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1645\u001b[0m     remove_from(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parameters, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_non_persistent_buffers_set)\n\u001b[0;32m   1646\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m _global_module_registration_hooks\u001b[39m.\u001b[39mvalues():\n",
      "\u001b[1;31mAttributeError\u001b[0m: cannot assign module before Module.__init__() call"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "  def __init__(self, output_size, embedding_dim, hidden_size, hidden_layer, dropout=0.2):\n",
    "    self.embedding = nn.Embedding.from_pretrained(embedding_matrix)\n",
    "    self.recurrent = nn.RNN(input_size=embedding_dim, \n",
    "             hidden_size=hidden_size, \n",
    "             num_layers=hidden_layer,\n",
    "             nonlinearity='relu',\n",
    "            #  dropout=dropout,\n",
    "             bidirectional=True)\n",
    "    self.out_layer = nn.Sequential(\n",
    "      nn.Linear(in_features=hidden_layer, out_features=output_size),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "  def forward(self, input):\n",
    "    emb = self.embedding(input)\n",
    "    out, ht = self.recurrent_stack(emb, None)\n",
    "    return out\n",
    "  \n",
    "model = RNN(OUTPUT_SIZE, EMBEDDINGS_DIM, HIDDEN_SIZE, 2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "\n",
    "train_loss_arr = []\n",
    "train_accu_arr = []\n",
    "val_loss_arr = []\n",
    "val_accu_arr = []\n",
    "\n",
    "def train(model, train_loader, val_loader, train_set, val_set, criterion, optimizer, num_epochs=50):\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    total_train_loss = 0\n",
    "    total_train_correct = 0\n",
    "    \n",
    "    model.train()\n",
    "    for input, target in train_loader:\n",
    "      if torch.cuda.is_available:\n",
    "        input, target = input.to(device), target.to(device)\n",
    "      \n",
    "      output = model(input)\n",
    "\n",
    "      loss = criterion(output, target)\n",
    "      total_train_loss += loss.items()\n",
    "      total_train_correct += ((output > 0.5)==target).sum()\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
